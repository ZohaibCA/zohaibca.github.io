<!DOCTYPE HTML>
<!--
	Zohaib Aftab, Data Scientist
	zohaibdr.github.io | 
	To showcase my projects
-->
<html>
	<head>
		<title>Project: Predicting Customer Churn </title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />

		<!-- Bootstrap CSS -->
		<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.4.1/dist/css/bootstrap.min.css" integrity="sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh" crossorigin="anonymous">

		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>

		<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

		<style>
			img{
				max-width: 90%;  
				display: block; /* remove extra space below image */
			}
		</style>

	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
						<a href="index.html" class="logo">Home</a>
					</header>

				<!-- Nav -->
				<nav id="nav">
					<ul class="links">
						<li class="active"><a href="index.html">Projects</a></li>
						<li><a href="resume.html">Resumé</a></li>
						<li><a href="Published.html">Published works</a></li>
					</ul>

					<ul class="icons">
						<li><a target="_blank" href="https://www.linkedin.com/in/drzohaib/" class="icon brands fa-linkedin"><span class="label">LinkedIn</span></a></li>
						<li><a target="_blank"  href=https://github.com/zohaibdr/DSportfolio_ class="icon brands fa-github"><span class="label">GitHub</span></a>
						</li>
						<li><a target="_blank"  href=mailto:zohaib@live.fr class="fa fa-envelope-open" style="font-size:22px"><span class="label"></span></a>
						</li>

					</ul>
				</nav>

				<!-- Main -->
					<div id="main">

		<section class="post">
			<header class="major">
				<h2> Preventing Customer Loss with ML </h2>
			</header>
			
			Tags: 
				Precision-Recall tradeoff &bull; ROC curve &bull; Stratified split  
				<hr />
				<ul class="actions">
					<li><a target = "_blank" href="https://github.com/zohaibdr/DSportfolio_" class="button primary">Python Code Here</a></li>
				</ul>

				<!-- <header> -->
				<h2>Context</h2>
				<p>Predicting churn rate is <strong>crucial</strong> for these companies because the cost of retaining an existing customer is far less than acquiring a new one. <strong>Machine learning</strong> helps companies analyze customer churn rate based on several factors such as services subscribed by customers, tenure rate, and the usage. </p>
				<p>The end goal of this project is to identify customers who are <strong>likely to leave</strong> a company, so that the company can take proactive steps to retain those customers. </p>

				
			<!-- </header> -->

			<h2><strong>Data I used:</strong></h2>
			<ol>
			  <li>Customers who left within the last month – the column is called ‘class’</li>
			  <li>Services that each customer has signed up for – international plan, voice mail plan, etc.</li>
			  <li>Customer account information and usage – how long they’ve been a customer, how much did they use each service</li>
			  <li>Their postal code</li>
			  <li>And finally, the number of customer service calls they made during this period</li>
			</ol>
			<p>There were a total of 5000 entries in the dataset (<em>source</em>).</p>
			
			<img src="images/customer_churn/data.png" alt="">
						<p> </p>
			<h2><strong>Exploratory data analysis</strong></h2>
			<p>During the EDA phase, I mainly asked the following three questions:</p>
			<ol>
				<li>Is the data balanced in terms of both classes (0 for customer who stayed, 1 for who churned)?</li>

			  <li>How many distinct areas did the customers come from and was there a specific area which showed a pattern?</li>
			  <li>Are there any redundant columns which may be removed?</li>
			  
			</ol>
			
			<h3>Answer to Q1:</h3>
			<ul>
				<li>Churn data is typically imbalanced where the minority class (the number of customers who churn) is often much smaller than the number of customers who do not churn. Here the class distribution is about 1:7 which is significant but not severe.

				</li>
				<img src="images/customer_churn/classes.png" alt="">
			  </ul>
			
			  <li> Any random guess would give us the accuracy of about 86% hence <strong>Accuracy would not the right metric to evaluate the model.</strong> 
				Plus I used <strong>stratified sampling</strong> in the <em> 'train_test_split' </em> to have fair distribution of minority class in both subsets of data. 

			  </li>

			  <p> </p>

			<h3>Answer to Q2:</h3>
			
			<ul>
				<li>There were 3 unique area codes (415, 408, 510). These were almost equally distributed in both classes. </li>
				<img src="images/customer_churn/byarea.png" alt="">
			  </ul>
			  <p> </p>
			<h3>Answer to Q3:</h3>
			<ul>
			  <li> Removed the 'phone_number' column. </li>
			  <li> Since total day minutes and charges are highly correlated (more minutes used mean more charge), I removed total minutes column for all categories (day, evening, etc).</li>
			</ul>
			
			
			
		<h2> Models</h2>
		<p> I implemented the following 5 classification algorithms using the sci-kit learn library: </p>
		<ol>
		  <li><strong>Logistic Regression</strong></li>
		  <li><strong>Support Vector Machine</strong></li>
		  <li><strong>K-Nearest Neighbors</strong></li>
		  <li><strong>Random Forest Classifier</strong></li>
		  <li><strong>Naïve Bayes</strong></li>
		</ol>
		<p>I compared them based on evaluation metrics such as <em>precision</em>, <em>recall</em>, and <em>F1-scores</em>, as well as <em>ROC curve</em> and <em>AUC scores</em>. These results are based on the test set of 1500 values (1280 + 220). The reported values are for positive class, wherever applicable.</p>



		<table style="width:100%; text-align:center; border: 1px solid rgb(0, 0, 0); font-size: 90%;">
				<tr style="background-color: #e0e0ee; font-size: 100%;">
				  <th style="text-align:center;">Classifier</th>
				  <th style="text-align:center;">Precision (%)</th>
				  <th style="text-align:center;">Recall (%)</th>
				  <th style="text-align:center;">F1-score (%)</th>
				  <th style="text-align:center;">AUC score</th>
				</tr>
				<tr>
				  <td>Logistic regression</td>
				  <td>60</td>
				  <td>19</td>
				  <td>28</td>
				  <td>0.81</td>
				</tr>
				<tr>
				  <td>Support vector machine</td>
				  <td>64</td>
				  <td>12</td>
				  <td>20</td>
				  <td>0.80</td>
				</tr>
				<tr style="background-color: #8bf163;">
				  <td>Random Forest</td>
				  <td>95</td>
				  <td>70</td>
				  <td>80</td>
				  <td>0.91</td>
				</tr>
				<tr>
				  <td>K-Nearest Neighbors</td>
				  <td>50</td>
				  <td>8</td>
				  <td>15</td>
				  <td>0.56</td>
				</tr>
				<tr>
				  <td>Naïve Bayes</td>
				  <td>50</td>
				  <td>38</td>
				  <td>43</td>
				  <td>0.85</td>
				</tr>
			</table>
			  
		<h2>Best classifier and interpretation of results</h2>
		<p>The Random Forest classifier came out to be the best classifier as evident from the table and the follwoing ROC curve.</p>
		<img src="images/customer_churn/ROC.png"/>
		<p>For the chosen classifier, the <strong>precision</strong> is 95%. This indicates that out of all the customers that the model predicted to leave, 95% of them actually did. This is good precision. The company can target those customers to retain those customers. </p>
			
		<p> Similarly, of all the customers who did leave, the model predicted the outcome with <b>70%</b> accuracy (<strong>recall</strong>). <strong>This means it is missing out 30% of leavers, which could be a big loss in terms of loss.</strong> 
</p>
<blockquote> 			
	We need to improve the recall score for our classifier for which analysis precision-recall tradeoff.</blockquote>


		<h2>The Precision-Recall tradeoff</h2>
		<p>I plotted the precision-recall graph for the random forest classifier and identified our current point.</p>
		<img src="images/customer_churn/PRecall.png"/>
		<p>Improving recall required sacrificing some precision. I wrote a small function to obtain at least <b>83%</b> recall:</p>

<pre><code># Calculate the recall and precision at DEFAULT setting
recall = recall_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
# Adjust the threshold to improve the recall 
desired_recall = 0.82   		#looking at the precision-recall curve, this seems like a good point 
while recall &lt; desired_recall:
	threshold -= 0.05
	y_pred = (y_prob &gt;= threshold).astype(int)
	recall = recall_score(y_test, y_pred)
	precision = precision_score(y_test, y_pred)
optim_threshold = threshold

print('At the threshold of %0.2f' %optim_threshold, ', the final recall is : %0.3f' %recall, 'while the precision is: %0.3f' %precision)
# At the threshold of 0.30 , the final recall is : 0.835 while the precision is: 0.808
</code></pre>

		<p>At the cut-off of <b>0.3</b>, I got a sweet-spot where both precision and recall were above 80%. This was chosen as an acceptable tradeoff.</p>


		<p>But which features are the best predictors?</p>
		<p>As a last step, I wanted to see which factors contribute the most to the prediction of customer churn. It turned out the <b>total day usage</b> was the top predictor of churn, followed by <b>number of customer service calls</b>.</p>
		<img src="images/customer_churn/FeatureImp.png"/>


<hr/> 

</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>