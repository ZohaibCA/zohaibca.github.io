<!DOCTYPE HTML>
<!--
	Zohaib Aftab, Data Scientist
	zohaibdr.github.io | 
	To showcase my projects
-->
<html>
	<head>
		<title>Project: Anomaly detection </title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<!-- Bootstrap CSS -->
		<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.4.1/dist/css/bootstrap.min.css" integrity="sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh" crossorigin="anonymous">

		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>

		<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

		<style>
			img{
				max-width: 90%;  
				display: block; /* remove extra space below image */
			}
		</style>

	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
						<a href="index.html" class="logo">Home</a>
					</header>

				<!-- Nav -->
				<nav id="nav">
					<ul class="links">
						<li class="active"><a href="index.html">Projects</a></li>
						<li><a href="resume.html">ResumÃ©</a></li>
						<li><a href="Published.html">Published works</a></li>
					</ul>

					<ul class="icons">
						<li><a target="_blank" href="https://www.linkedin.com/in/drzohaib/" class="icon brands fa-linkedin"><span class="label">LinkedIn</span></a></li>
						<li><a target="_blank"  href=https://github.com/zohaibdr/DSportfolio_ class="icon brands fa-github"><span class="label">GitHub</span></a>
						</li>
						<li><a target="_blank"  href=mailto:zohaib@live.fr class="fa fa-envelope-open" style="font-size:22px"><span class="label"></span></a>
						</li>

					</ul>
				</nav>
				<!-- Main -->
					<div id="main">

						<!-- Post -->
		<section class="post">
			<header class="major">
				<h2> AI-powered Anomaly Detection </h2>
			</header>

			Tags: 
				Time series data &bull; Business Intelligence 
				<hr />
				
			<!-- Text stuff -->
			<!-- <header> -->
				<h2> Context </h2>
				<p>  Taxi-out time is the time between the plane leaving the gates and actually taking off. It is the amount of time an aircraft spends in movement on the surface of an airport. High taxi-out times not only lead to flight delays, but also result in higher aircraft fuel consumption. Flagging unwanted spikes in the taxi-out times is essential for airport authorities. 
				</p> 
				<p> <span class="image fit"> <img src="images\airline_anomaly\Taxiout.png" alt="" /> </span> </p>

				<p> 
					<strong> But the question is: How to define an 'abnormal' taxi-out time?</strong> <br> 
					There is a lot of variation in what would be considered normal taxi-out time depending upon various factors as origin of the flight, airport schedule, etc. 
				</p>

				<h2> Ways to address sans ML </h2>
				<p> A simple benchmark for the airport will be to flag any days where this time exceeds a set limit (say 15 minutes) or the overall average taxi-out times. However, it wouldn't be practical as it will result in too many flags being raised which do not necessary need attention. 

					<p> Another way would be to set a semi-dynamic time limit like 90th or 95th pecentile threshold for the airport. All daily taxi averages which exceed this threshold would be flagged. It could work, but is prone to be affected by outliers. For example, when there comes a day of high taxi-out times (due to weather or a specific day of the week), the bar would be set to high unnecesarity for the next day. 
						<p> 
							 <blockquote> ðŸ’¡ The prediction model needs to take into account 'contextual' factors by understanding the pattern of the data. </blockquote>
						</p>
					</p> 
					 </p>


			<h2> ML-based Solution </h2>
			<p> This brings us to the Anomaly Detection using machine learning. 
				Anomaly detection is identifying data points in data that don't fit the normal patterns. 
				<strong> sdfs </strong> 
				
				 </p>
			
				<h3> Data set </h3>
					One month historical data of all American airlines (over 37000 entries)
					<br>
					Source: Book: AI-Powered Business Intelligence <a href="https://www.amazon.com/-/de/dp/1098111478/" target="_blank">(https://www.amazon.com/-/de/dp/1098111478/) </a> 

			</header>

				<hr />
				<!-- <header> -->
					<h1>Strategy</h1>
						<h2> From PowerBI to Azure and back... </h2>

					<p> Our target is to design an intuitive report for the end-user while leveraging ML at the same time. For this purpose, we use <strong>Microsoft Azure AI service</strong> which is called in the Microsoft PowerBI report. The <strong>Anomaly Detector</strong> in Azure is a pretrained model which will detect upper and lower bounds on the expected taxi-out values. 
					</p> 
This is how it looks like on Azure Portal: 
					<p> <span class="image fit"> <img src="images\airline_anomaly\Azure 1.png" alt="" /> </span> </p>
					
					It provides us with the keys and endpoints which we integrate in our application while accessing this model: 

					<p> <span class="image fit"> <img src="images\airline_anomaly\Azure keys.png" alt="" /> </span> </p>

					
The code for the integration of this model in our PowerBI report is below [Courtesy: <a href="https://www.amazon.com/-/de/dp/1098111478/"> (Link) </a>]: 
					
<pre>
	<code> 
# SECTION 0: Setup and Variables ----

import pandas as pd
import requests
import json

API_KEY = "---"  #from the portal 
API_URL = "https://taxianomaly.cognitiveservices.azure.com/anomalydetector/v1.0/timeseries/entire/detect"
REGION = 'eastus2'

# In order to narrow down our analysis, we only consider airports with at least 1000 flights in the month  
MIN_FLIGHTS = 1000


# SECTION 1: API Request Function ----

# Expects a list of columns and gets predictions for each row 
def inference_request(timestamp, value, granularity):
	
# Build request dataframe based on timestamp and value
request_df = pd.DataFrame({"timestamp": timestamp, "value": value})

# Build JSON object for request body
series = list(request_df.to_dict('records'))
req = dict({"series": series, "granularity": granularity})

# POST request - send JSON to API
headers = {'Ocp-Apim-Subscription-Key': API_KEY, 
		'Content-Type': 'application/json',
		'Ocp-Apim-Subscription-Region': REGION}

result = requests.post(API_URL, data = json.dumps(req), headers=headers)
return(result)


# SECTION 2: Data preprocessing

# Fetch dataset variable from Power BI and convert Timestamp to string
df = dataset

# Get airports where threshold is met
airports = (df
			.groupby("Origin")
			.agg(n=('Origin', 'count'))
			.query("n > @MIN_FLIGHTS")
			.sort_values("n", ascending = False))

df_inference_all = pd.DataFrame()

# SECTION 3: Get Predictions 

# Loop through all airports in list and calculate average Taxi Out time
for airport in airports.index:

	# Create aggregated dataframe for average TaxiOut per Airport 
	df_inference = (df.filter(items = ['FlightDateTxt', 'Origin', 'TaxiOut'])
					.query("Origin == @airport")
					.groupby(['FlightDateTxt', 'Origin'])
					.agg(AvgTaxiOut=('TaxiOut', 'mean'))
					.reset_index())
	df_inference['Timestamp'] = df_inference['FlightDateTxt'] + "T00:00:00Z"
	df_inference['AvgTaxiOut'] = df_inference['AvgTaxiOut'].round(2)

	# Submit request to get anomaly predictions
	result = inference_request(df_inference['Timestamp'], df_inference['AvgTaxiOut'], "daily")
	result = result.content

	# Convert result object to dataframe
	results_df = pd.DataFrame(json.loads(result))

	# Add inference results to inference_df (collects results for all airports)
	df_inference = pd.concat([df_inference, results_df], axis = 1).drop(columns=['Timestamp'])

	df_inference_all = pd.concat([df_inference_all, df_inference])
	
	
# SECTION 4: Data postprocessing 

# Add inference information to original dataframe
df_inference_all = df_inference_all.reset_index(drop = True)
df = df.merge(df_inference_all, "left", on = ["FlightDateTxt", "Origin"])
df['upperMargins'] = df['expectedValues'] + df['upperMargins']
df['lowerMargins'] = df['expectedValues'] - df['lowerMargins']


# SECTION 5: Format output for Power BI 

output = pd.DataFrame(df.copy())
del df_inference
del df_inference_all 
del results_df
del df


</code>
</pre>

<blockquote> <strong>Both of these tests are repeated at other key thresholds ($2000,$3000 and $5000) with similar results of failing to reject the null hypothesis (no age and gender effect)</strong>. </blockquote> 

<hr />

<h2> Back to business </h2>


		<hr />
									
		<h1>Results</h1>
		The result of 

		<p> <span class="image fit"> <img src="images\airline_anomaly\Taxiout.png" alt="" /> </span> </p>

<strong>		The regression coefficient for the true threshold was statistically significant with an estimated impact of around $278.  This is much larger than the $50 per customer needed to run this higher recovery strategy.
</strong>
Similar analysis is performed for all thresholds with the results summarized in the table below: <br>

<p> <span class="image fit"> <img src="images\airline_anomaly\Taxiout.png" alt="" /> </span> </p>


		<h1>Conclusion</h1>
		<div class="box">
To conclude, it is worth chasing the smaller loans, by changing the strategy at each of the first three strategy levels. However, for the loans greater than $5000, it is not worth investing in Level 4 strategy. 
</div>

									<hr />


							</section>

					</div>

			

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>